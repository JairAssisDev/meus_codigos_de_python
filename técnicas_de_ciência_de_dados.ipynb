{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLx/QiggnoPTCRx+kDXvhr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JairAssisDev/meus_codigos_de_python/blob/main/t%C3%A9cnicas_de_ci%C3%AAncia_de_dados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalização"
      ],
      "metadata": {
        "id": "NJKIVLztcqqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "utXe10ofc2q9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdJxYFJGWKpA",
        "outputId": "6a68d559-82cc-4a12-b7ea-49f97ef60624"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados originais: [ 2.  5. 10. 15. 20.]\n",
            "Dados escalonados Min-Max: [0.         0.16666667 0.44444444 0.72222222 1.        ]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "data = np.array([2.0, 5.0, 10.0, 15.0, 20.0])\n",
        "\n",
        "# Calcule o mínimo e o máximo dos dados\n",
        "min_value = np.min(data)\n",
        "max_value = np.max(data)\n",
        "\n",
        "# Aplique o escalonamento Min-Max\n",
        "scaled_data = (data - min_value) / (max_value - min_value)\n",
        "\n",
        "print(\"Dados originais:\", data)\n",
        "print(\"Dados escalonados Min-Max:\", scaled_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CD906TlNc3MV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "data = np.array([2.0, 5.0, 10.0, 15.0, 20.0])\n",
        "\n",
        "# Calcule a média e o desvio padrão dos dados\n",
        "mean = np.mean(data)\n",
        "std_dev = np.std(data)\n",
        "\n",
        "# Aplique a padronização Z-Score\n",
        "standardized_data = (data - mean) / std_dev\n",
        "\n",
        "print(\"Dados originais:\", data)\n",
        "print(\"Dados padronizados Z-Score:\", standardized_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOMf1VLBW4RB",
        "outputId": "f59a55d8-249d-4b7e-aa88-7130f3efa004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados originais: [ 2.  5. 10. 15. 20.]\n",
            "Dados padronizados Z-Score: [-1.28638417 -0.82696125 -0.06125639  0.70444848  1.47015334]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pNvN2zwwc30l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "data = np.array([2.0, 5.0, 10.0, 15.0, 200.0])\n",
        "\n",
        "# Calcule a mediana e o IQR dos dados\n",
        "median = np.median(data)\n",
        "iqr = np.percentile(data, 75) - np.percentile(data, 25)\n",
        "\n",
        "# Aplique a escala robusta\n",
        "robust_scaled_data = (data - median) / iqr\n",
        "\n",
        "print(\"Dados originais:\", data)\n",
        "print(\"Dados escalonados robustamente:\", robust_scaled_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNl4omKoXRUh",
        "outputId": "b47c2972-9652-4019-b737-95d56f67dfe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados originais: [  2.   5.  10.  15. 200.]\n",
            "Dados escalonados robustamente: [-0.8 -0.5  0.   0.5 19. ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nLFB2LLzc4Q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "data = np.array([1.0, 2.0, 4.0, 8.0, 16.0])\n",
        "\n",
        "# Aplique a transformação logarítmica (ln)\n",
        "log_transformed_data = np.log(data)\n",
        "\n",
        "print(\"Dados originais:\", data)\n",
        "print(\"Dados após transformação logarítmica (ln):\", log_transformed_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc2JbOeKXuvR",
        "outputId": "23074c68-c3ac-4ec8-dc85-7c8e043aacf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados originais: [ 1.  2.  4.  8. 16.]\n",
            "Dados após transformação logarítmica (ln): [0.         0.69314718 1.38629436 2.07944154 2.77258872]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GqkQsenac4yG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "\n",
        "data = np.array([1.0, 2.0, 4.0, 8.0, 16.0])\n",
        "\n",
        "# Aplique a transformação Box-Cox\n",
        "transformed_data, lambda_value = stats.boxcox(data)\n",
        "\n",
        "print(\"Dados originais:\", data)\n",
        "print(\"Dados após a transformação Box-Cox:\", transformed_data)\n",
        "print(\"Valor lambda estimado:\", lambda_value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QhnnMSUYEoo",
        "outputId": "84a393d4-817f-407f-a809-4c6de3664722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados originais: [ 1.  2.  4.  8. 16.]\n",
            "Dados após a transformação Box-Cox: [0.         0.69314718 1.38629437 2.07944157 2.77258877]\n",
            "Valor lambda estimado: 1.204940897059359e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zmzBwYVFc5g1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "data = np.array([2.0, 5.0, 10.0, 15.0, 20.0])\n",
        "\n",
        "# Calcule a magnitude do vetor\n",
        "magnitude = np.linalg.norm(data)\n",
        "\n",
        "# Aplique a escala de vetor unitário\n",
        "unit_vector_scaled_data = data / magnitude\n",
        "\n",
        "print(\"Dados originais:\", data)\n",
        "print(\"Dados escalonados para o vetor unitário:\", unit_vector_scaled_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z67XzkqUav1w",
        "outputId": "fc26ef64-153d-420b-beff-1891d33706e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados originais: [ 2.  5. 10. 15. 20.]\n",
            "Dados escalonados para o vetor unitário: [0.0728357  0.18208926 0.36417852 0.54626778 0.72835704]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imputação de Dados"
      ],
      "metadata": {
        "id": "uojhylGJ6pHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Média/mediana/mode imputation"
      ],
      "metadata": {
        "id": "-KipROhxgyoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Exemplo de DataFrame com valores ausentes\n",
        "data = {'A': [1, 2, None, 4, 5],\n",
        "        'B': [None, 6, 7, 8, 9],\n",
        "        'C': [10, 11, 12, None, 14]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Imputação da média\n",
        "df_mean_filled = df.fillna(df.mean())\n",
        "print(\"DataFrame com imputação da média:\")\n",
        "print(df_mean_filled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMl2bXPu6tmJ",
        "outputId": "a951ee6f-c6ff-40ba-c715-af5e94c2e9a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame com imputação da média:\n",
            "     A    B      C\n",
            "0  1.0  7.5  10.00\n",
            "1  2.0  6.0  11.00\n",
            "2  3.0  7.0  12.00\n",
            "3  4.0  8.0  11.75\n",
            "4  5.0  9.0  14.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Nearest Neighbors (KNN) imputation"
      ],
      "metadata": {
        "id": "2rRU_BbMgsxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "# Exemplo de DataFrame com valores ausentes\n",
        "data = {'A': [1, 2, None, 4, 5],\n",
        "        'B': [None, 6, 7, 8, 9],\n",
        "        'C': [10, 11, 12, None, 14]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Inicialização do KNNImputer com 2 vizinhos mais próximos\n",
        "imputer = KNNImputer(n_neighbors=2)\n",
        "\n",
        "# Preenchimento dos valores ausentes usando KNNImputer\n",
        "df_knn_filled = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
        "\n",
        "# Impressão do DataFrame com os valores imputados usando KNN\n",
        "print(\"DataFrame com imputação KNN:\")\n",
        "print(df_knn_filled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgfFlUFcav5h",
        "outputId": "30f11760-97d0-4c96-b5fe-c8fb61439cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame com imputação KNN:\n",
            "     A    B     C\n",
            "0  1.0  6.5  10.0\n",
            "1  2.0  6.0  11.0\n",
            "2  3.0  7.0  12.0\n",
            "3  4.0  8.0  13.0\n",
            "4  5.0  9.0  14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imputação por regressão"
      ],
      "metadata": {
        "id": "QrB5Lt9igrJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Exemplo de DataFrame com valores ausentes\n",
        "data = {'A': [1, 2, None, 4, 5],\n",
        "        'B': [None, 6, 7, 8, 9],\n",
        "        'C': [10, 11, 12, None, 14]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Preenchimento dos valores ausentes usando SimpleImputer com a estratégia de média\n",
        "for col in df.columns:\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    df_col = pd.DataFrame(imputer.fit_transform(df[[col]]))\n",
        "    df[col] = df_col\n",
        "\n",
        "# Impressão do DataFrame com os valores imputados usando SimpleImputer\n",
        "print(\"DataFrame com imputação por média:\")\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pwkd8cT2gdIJ",
        "outputId": "d3789fbb-3a4f-4335-9d71-0e3dbe01297c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame com imputação por média:\n",
            "     A    B      C\n",
            "0  1.0  7.5  10.00\n",
            "1  2.0  6.0  11.00\n",
            "2  3.0  7.0  12.00\n",
            "3  4.0  8.0  11.75\n",
            "4  5.0  9.0  14.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MICE"
      ],
      "metadata": {
        "id": "W3dzL7ktglvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install impyute\n",
        "\n",
        "import pandas as pd\n",
        "import impyute as impy\n",
        "\n",
        "# Exemplo de DataFrame com valores ausentes\n",
        "data = {'A': [1, 2, None, 4, 5],\n",
        "        'B': [None, 6, 7, 8, 9],\n",
        "        'C': [10, 11, 12, None, 14]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Imputação dos valores ausentes usando MICE\n",
        "df_mice_filled = impy.mice(df.values)\n",
        "\n",
        "# Conversão do resultado de volta para DataFrame\n",
        "df_mice_filled = pd.DataFrame(df_mice_filled, columns=df.columns)\n",
        "\n",
        "# Impressão do DataFrame com os valores imputados usando MICE\n",
        "print(\"DataFrame com imputação MICE:\")\n",
        "print(df_mice_filled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3C6w3m6lgdwj",
        "outputId": "b4d83635-5a88-4991-a865-6f539d4d80d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting impyute\n",
            "  Downloading impyute-0.0.8-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from impyute) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from impyute) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from impyute) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->impyute) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->impyute) (3.2.0)\n",
            "Installing collected packages: impyute\n",
            "Successfully installed impyute-0.0.8\n",
            "DataFrame com imputação MICE:\n",
            "[[ 1.  5. 10.]\n",
            " [ 2.  6. 11.]\n",
            " [ 3.  7. 12.]\n",
            " [ 4.  8. 13.]\n",
            " [ 5.  9. 14.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrix Factorization Techniques"
      ],
      "metadata": {
        "id": "EwQqXeKFgi_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fancyimpute\n",
        "\n",
        "import pandas as pd\n",
        "import fancyimpute\n",
        "\n",
        "# Exemplo de DataFrame com valores ausentes\n",
        "data = {'A': [1, 2, None, 4, 5],\n",
        "        'B': [None, 6, 7, 8, 9],\n",
        "        'C': [10, 11, 12, None, 14]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Imputação dos valores ausentes usando técnicas de fatorização de matrizes\n",
        "df_matrix_filled = pd.DataFrame(fancyimpute.MatrixFactorization().fit_transform(df))\n",
        "\n",
        "# Impressão do DataFrame com os valores imputados usando fatorização de matrizes\n",
        "print(\"DataFrame com imputação por técnicas de fatorização de matrizes:\")\n",
        "print(df_matrix_filled)\n"
      ],
      "metadata": {
        "id": "h3L5WtVpgdco",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e43f4cdc-6e43-4ff7-c1ea-fb9e80bf7da1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fancyimpute\n",
            "  Downloading fancyimpute-0.7.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting knnimpute>=0.1.0 (from fancyimpute)\n",
            "  Downloading knnimpute-0.1.0.tar.gz (8.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (1.2.2)\n",
            "Requirement already satisfied: cvxpy in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (1.3.2)\n",
            "Requirement already satisfied: cvxopt in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (1.3.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (7.4.2)\n",
            "Collecting nose (from fancyimpute)\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.10/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (3.2.0)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (0.6.2.post8)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (2.0.12)\n",
            "Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (3.2.3)\n",
            "Requirement already satisfied: setuptools>65.5.1 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (67.7.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (23.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (1.1.3)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (2.0.1)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.4.1->cvxpy->fancyimpute) (0.1.7.post0)\n",
            "Building wheels for collected packages: fancyimpute, knnimpute\n",
            "  Building wheel for fancyimpute (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fancyimpute: filename=fancyimpute-0.7.0-py3-none-any.whl size=29880 sha256=6f67c703f06e147e747c0a9fbaf5aaa7500688486d08b120707e36f7243d3ee9\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/0c/d3/ee82d1fbdcc0858d96434af108608d01703505d453720c84ed\n",
            "  Building wheel for knnimpute (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for knnimpute: filename=knnimpute-0.1.0-py3-none-any.whl size=11329 sha256=0a2eaa9d8f2d9870f2c73d5b3dcd941838f914bfb03eb639dc4193af57c5b883\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/06/a5/45a724630562413c374e29c08732411d496092408b3a7bf754\n",
            "Successfully built fancyimpute knnimpute\n",
            "Installing collected packages: nose, knnimpute, fancyimpute\n",
            "Successfully installed fancyimpute-0.7.0 knnimpute-0.1.0 nose-1.3.7\n",
            "[MatrixFactorization] Iter 10: observed MAE=2.291990 rank=40\n",
            "[MatrixFactorization] Iter 20: observed MAE=1.544100 rank=40\n",
            "[MatrixFactorization] Iter 30: observed MAE=1.011980 rank=40\n",
            "[MatrixFactorization] Iter 40: observed MAE=0.661462 rank=40\n",
            "[MatrixFactorization] Iter 50: observed MAE=0.479671 rank=40\n",
            "DataFrame com imputação por técnicas de fatorização de matrizes:\n",
            "          0         1          2\n",
            "0  1.000000  6.068417  10.000000\n",
            "1  2.000000  6.000000  11.000000\n",
            "2  4.187424  7.000000  12.000000\n",
            "3  4.000000  8.000000  10.937851\n",
            "4  5.000000  9.000000  14.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pipeline"
      ],
      "metadata": {
        "id": "KX0z9MUUnisJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pré-processamento e transformações de dados"
      ],
      "metadata": {
        "id": "KwyMfbQwnk1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Exemplo de DataFrame com valores ausentes\n",
        "data = {'A': [1, 2, None, 4, 5],\n",
        "        'B': [None, 6, 7, 8, 9],\n",
        "        'C': [10, 11, 12, None, 14]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Criando o pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Aplicando o pipeline\n",
        "df_transformed = pipeline.fit_transform(df)\n",
        "df_transformed = pd.DataFrame(df_transformed, columns=df.columns)\n",
        "\n",
        "# Imprimindo o DataFrame transformado\n",
        "print(\"DataFrame após o pipeline de pré-processamento e transformação:\")\n",
        "print(df_transformed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n0bY3QEnnvg",
        "outputId": "ecfe04af-edf6-4dc5-f4d1-0f561733b56e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame após o pipeline de pré-processamento e transformação:\n",
            "          A    B         C\n",
            "0 -1.414214  0.0 -1.322876\n",
            "1 -0.707107 -1.5 -0.566947\n",
            "2  0.000000 -0.5  0.188982\n",
            "3  0.707107  0.5  0.000000\n",
            "4  1.414214  1.5  1.700840\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Union"
      ],
      "metadata": {
        "id": "a657OUmLnv3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Exemplo de DataFrame com valores ausentes\n",
        "data = {'A': [1, 2, None, 4, 5],\n",
        "        'B': [None, 6, 7, 8, 9],\n",
        "        'C': [10, 11, 12, None, 14]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Removendo os valores ausentes\n",
        "df = df.dropna()\n",
        "\n",
        "# Criando o pipeline com FeatureUnion\n",
        "pipeline = Pipeline([\n",
        "    ('union', FeatureUnion([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('pca', PCA(n_components=2))\n",
        "    ]))\n",
        "])\n",
        "\n",
        "# Aplicando o pipeline\n",
        "df_transformed = pipeline.fit_transform(df)\n",
        "print(\"DataFrame após o pipeline com FeatureUnion:\")\n",
        "print(df_transformed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMya_d5HnxHB",
        "outputId": "7cbad703-3526-4370-b0bf-4ab7bcedd6af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame após o pipeline com FeatureUnion:\n",
            "[[-1.         -1.         -1.          2.          6.         11.\n",
            "  -2.59807621  0.        ]\n",
            " [ 1.          1.          1.          5.          9.         14.\n",
            "   2.59807621  0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grid Search"
      ],
      "metadata": {
        "id": "TCIwE0ESn_dR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Gerando um conjunto de dados de exemplo\n",
        "X, y = make_regression()\n",
        "param_grid = {'n_estimators': [10, 100, 1000]}\n",
        "\n",
        "# Criando o pipeline com GridSearchCV\n",
        "pipeline = Pipeline([\n",
        "    ('regressor', GridSearchCV(RandomForestRegressor(), param_grid))\n",
        "])\n",
        "\n",
        "# Aplicando o pipeline\n",
        "pipeline.fit(X, y)\n",
        "print(\"Melhores parâmetros encontrados pelo Grid Search:\")\n",
        "print(pipeline.named_steps['regressor'].best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vFe-FQ6oAEx",
        "outputId": "906938ee-c84b-4d09-e481-5bc076b7944e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melhores parâmetros encontrados pelo Grid Search:\n",
            "{'n_estimators': 1000}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensemble Methods"
      ],
      "metadata": {
        "id": "G4UaKq7voE9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Exemplo de conjunto de dados\n",
        "X, y = make_classification()\n",
        "\n",
        "# Criando o pipeline com VotingClassifier\n",
        "pipeline = Pipeline([\n",
        "    ('ensemble', VotingClassifier(estimators=[\n",
        "        ('lr', LogisticRegression()),\n",
        "        ('gnb', GaussianNB()),\n",
        "        ('rf', RandomForestClassifier())\n",
        "    ]))\n",
        "])\n",
        "\n",
        "# Aplicando o pipeline\n",
        "pipeline.fit(X, y)\n",
        "print(\"Resultado do ensemble de classificadores:\")\n",
        "print(pipeline.score(X, y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33JxgmSQoAsh",
        "outputId": "39cac999-db59-4305-c1cd-2ac0dfb98bdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultado do ensemble de classificadores:\n",
            "0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avaliação de Modelos"
      ],
      "metadata": {
        "id": "CA1tpGLWoIjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Carregando o conjunto de dados de exemplo\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Criando o pipeline com avaliação de modelo\n",
        "pipeline = Pipeline([\n",
        "    ('clf', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Aplicando o pipeline com validação cruzada\n",
        "scores = cross_val_score(pipeline, X, y, cv=5)\n",
        "print(\"Resultados da validação cruzada:\")\n",
        "print(scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2FU3JKYoJTZ",
        "outputId": "0edaa6d1-5c11-4e01-9e3c-40f89a0d4e06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados da validação cruzada:\n",
            "[0.96666667 1.         0.93333333 0.96666667 1.        ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    }
  ]
}